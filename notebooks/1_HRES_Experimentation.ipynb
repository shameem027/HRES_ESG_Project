{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## HRES PhD Framework Experimentation Notebook\n",
    "**Author:** Md Shameem Hossain\n",
    "**Purpose:** This notebook is used for ad-hoc analysis, scenario testing, and logging experimental runs of the HRES Decision Engine to MLflow. It also demonstrates how to package the decision logic as a versioned model in the MLflow Model Registry."
   ],
   "id": "77cec9302aad1193"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import sys\n",
    "import os\n",
    "import json # Added for json.dumps in MCDA model packaging\n",
    "\n",
    "# Add the src directory to the Python path so this notebook can import our custom modules.\n",
    "# This path is specific to the Jupyter container's WORKDIR and volume mounts.\n",
    "sys.path.append('/home/jovyan/src')\n",
    "\n",
    "# Import the definitive, class-based decision engine and ML predictor\n",
    "from MCDA_model import HRES_Decision_Engine\n",
    "from HRES_ML_Model import HRESMLPredictor\n",
    "\n",
    "# --- 1. Load Resources ---\n",
    "# Load the comprehensive dataset that was generated by our simulation engine\n",
    "DATA_PATH = \"/home/jovyan/src/HRES_Dataset.csv\"\n",
    "try:\n",
    "    hres_df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"‚úÖ Successfully loaded dataset from {DATA_PATH} with {len(hres_df)} configurations.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Dataset file not found at {DATA_PATH}. Please run HRES_Dataset_Generator.py first.\")\n",
    "    hres_df = pd.DataFrame() # Create empty DataFrame to prevent further errors\n",
    "\n",
    "# Instantiate our decision engine with the loaded data\n",
    "decision_engine = HRES_Decision_Engine(hres_df)\n",
    "print(f\"‚úÖ HRES Decision Engine initialized.\")\n",
    "\n",
    "# --- 2. MLflow Setup ---\n",
    "# This URI points to the mlflow service defined in our docker-compose.yml\n",
    "MLFLOW_TRACKING_URI = \"http://hres_mlflow:5000\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "EXPERIMENT_NAME = \"HRES_Decision_Scenarios_PhD\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"‚úÖ MLflow connection successful. Using experiment '{EXPERIMENT_NAME}'.\")"
   ],
   "id": "b63df8aa4dec351f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Run and Log Benchmark Scenarios\n",
    "Here, we define several test scenarios with different user priorities. We then run each one through the full decision pipeline and log all inputs, outputs, and metadata to MLflow for tracking and comparison."
   ],
   "id": "ac44f8ed9449685b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scenarios = {\n",
    "    \"University_High_ESG\": {\n",
    "        \"scenario_name\": \"University_Campus\",\n",
    "        \"annual_demand_kwh\": 3000000,\n",
    "        \"user_grid_dependency_pct\": 15,\n",
    "        \"esg_weights\": {\"environment\": 0.5, \"social\": 0.4, \"governance\": 0.1, \"cost\": 0.0}\n",
    "    },\n",
    "    \"Office_Cost_Focused\": {\n",
    "        \"scenario_name\": \"Small_Office\",\n",
    "        \"annual_demand_kwh\": 250000,\n",
    "        \"user_grid_dependency_pct\": 40,\n",
    "        \"esg_weights\": {\"environment\": 0.1, \"social\": 0.1, \"governance\": 0.0, \"cost\": 0.8}\n",
    "    },\n",
    "    \"Hospital_Resilience_Focused\": {\n",
    "        \"scenario_name\": \"Hospital\",\n",
    "        \"annual_demand_kwh\": 1500000,\n",
    "        \"user_grid_dependency_pct\": 10,\n",
    "        \"esg_weights\": {\"environment\": 0.2, \"social\": 0.6, \"governance\": 0.1, \"cost\": 0.1}\n",
    "    },\n",
    "    \"DataCenter_LowGrid_BalancedESG\": {\n",
    "        \"scenario_name\": \"Data_Center\",\n",
    "        \"annual_demand_kwh\": 10000000,\n",
    "        \"user_grid_dependency_pct\": 5, # Very low grid dependency\n",
    "        \"esg_weights\": {\"environment\": 0.3, \"social\": 0.3, \"governance\": 0.2, \"cost\": 0.2}\n",
    "    }\n",
    "}\n",
    "\n",
    "for run_name, params in scenarios.items():\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        print(f\"--- Running scenario: {run_name} ---\")\n",
    "        # Log input parameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        best_solution, status, feasible_df, sorted_df, pareto_df = decision_engine.run_full_pipeline(\n",
    "            params[\"scenario_name\"],\n",
    "            params[\"annual_demand_kwh\"],\n",
    "            params[\"user_grid_dependency_pct\"],\n",
    "            params[\"esg_weights\"]\n",
    "        )\n",
    "\n",
    "        mlflow.set_tag(\"status\", status)\n",
    "\n",
    "        if best_solution is not None:\n",
    "            # Log all KPIs from the recommended solution as metrics in MLflow\n",
    "            # Exclude 'model_constants' as it's a dict, not a simple metric\n",
    "            metrics_to_log = best_solution.drop(['scenario_name', 'esg_category', 'annual_demand_kwh']).to_dict()\n",
    "            cleaned_metrics = {k: v for k, v in metrics_to_log.items() if isinstance(v, (int, float))}\n",
    "            mlflow.log_metrics(cleaned_metrics)\n",
    "\n",
    "            # Log the full recommendation as an artifact\n",
    "            with open(f\"/tmp/best_solution_{run_name}.json\", \"w\") as f: # Save to /tmp for artifacts\n",
    "                json.dump(best_solution.to_dict(), f, indent=2)\n",
    "            mlflow.log_artifact(f\"/tmp/best_solution_{run_name}.json\")\n",
    "\n",
    "            print(f\"‚úÖ Success. Logged recommendation to MLflow. Run ID: {run.info.run_id}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No solution found for this scenario. Status: {status}\")\n",
    "\n",
    "print(\"\\nüéâ All scenarios have been run and logged to MLflow.\")"
   ],
   "id": "15d2b848ba1b12f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train and Register ML Prediction Models\n",
    "This section demonstrates how to train simple ML models (Random Forests) using the generated dataset to predict key HRES outcomes. These models are logged and registered with MLflow, enabling faster inference for the 'ML Fast Predictor' UI tab."
   ],
   "id": "786f3e121eb12621"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not hres_df.empty:\n",
    "    predictor = HRESMLPredictor(model_name_suffix=\"_V1\")\n",
    "    predictor.train_and_log_models(DATA_PATH)\n",
    "else:\n",
    "    print(\"‚ùå Skipping ML model training: Dataset is empty.\")"
   ],
   "id": "7a3840ca7341524b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Package and Register the Decision Logic (MCDA Model)\n",
    "To meet MLOps requirements for governance and reproducibility, we package our `HRES_Decision_Engine` class into a standard `mlflow.pyfunc` format. This allows us to register it as a versioned model in the MLflow Model Registry, creating an immutable, auditable link between a model version and the results it produces."
   ],
   "id": "3d2cc23d1cd9f37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import mlflow.pyfunc\n",
    "import json\n",
    "\n",
    "MODEL_NAME_MCDA = \"HRES-MCDA-Decision-Engine\"\n",
    "\n",
    "# Create a wrapper class to make our custom logic compatible with the mlflow.pyfunc standard.\n",
    "class HRES_Engine_Wrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        # This method runs once when the model is loaded.\n",
    "        # FIX: Use the correct dataset path, as specified in the Docker mounts.\n",
    "        DATA_PATH_IN_CONTAINER = \"/home/jovyan/src/HRES_Dataset.csv\"\n",
    "\n",
    "        # Ensure src is in path for MCDA_model import\n",
    "        if '/home/jovyan/src' not in sys.path:\n",
    "            sys.path.append('/home/jovyan/src')\n",
    "\n",
    "        # The MCDA_model relies on HRES_Dataset_Generator constants, so we ensure generator is importable too\n",
    "        import HRES_Dataset_Generator # Just importing it to make constants available for MCDA_model\n",
    "\n",
    "        hres_df_loaded = pd.read_csv(DATA_PATH_IN_CONTAINER)\n",
    "        from MCDA_model import HRES_Decision_Engine\n",
    "        self.engine = HRES_Decision_Engine(hres_df_loaded)\n",
    "        print(\"‚úÖ HRES_Engine_Wrapper loaded context and initialized Decision Engine.\")\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # This method runs for every prediction request.\n",
    "        results = []\n",
    "        for _, row in model_input.iterrows():\n",
    "            # The input will be a DataFrame, extract parameters\n",
    "            scenario_name = row['scenario_name']\n",
    "            annual_demand_kwh = row['annual_demand_kwh']\n",
    "            user_grid_dependency_pct = row['user_grid_dependency_pct']\n",
    "            esg_weights = json.loads(row['esg_weights']) # json.loads() to convert string back to dict\n",
    "\n",
    "            solution, status, _, _, _ = self.engine.run_full_pipeline(\n",
    "                scenario_name,\n",
    "                annual_demand_kwh,\n",
    "                user_grid_dependency_pct,\n",
    "                esg_weights\n",
    "            )\n",
    "            if solution is not None:\n",
    "                res_dict = solution.to_dict()\n",
    "                res_dict['status'] = status\n",
    "                results.append(res_dict)\n",
    "            else:\n",
    "                results.append({'status': status, 'recommendation': None})\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "# Log and register the wrapped MCDA model logic\n",
    "if not hres_df.empty:\n",
    "    with mlflow.start_run(run_name=\"Package_and_Register_MCDA_Logic\") as run:\n",
    "        # Example input for model signature\n",
    "        input_example = pd.DataFrame([{\\\n",
    "            \"scenario_name\": \"University_Campus\",\\\n",
    "            \"annual_demand_kwh\": 3000000,\\\n",
    "            \"user_grid_dependency_pct\": 15.0,\\\n",
    "            \"esg_weights\": json.dumps({\"environment\": 0.5, \"social\": 0.4, \"governance\": 0.1, \"cost\": 0.0})\\\n",
    "        }])\n",
    "\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"mcda_model_logic\",\n",
    "            python_model=HRES_Engine_Wrapper(),\n",
    "            input_example=input_example,\n",
    "            registered_model_name=MODEL_NAME_MCDA,\n",
    "            conda_env={\\\n",
    "                'channels': ['conda-forge'],\\\n",
    "                'dependencies': [\\\n",
    "                    'python=3.9',\\\n",
    "                    'pandas',\\\n",
    "                    'numpy',\\\n",
    "                    'scikit-learn',\\\n",
    "                    'tqdm',\\\n",
    "                    'psycopg2-binary',\\\n",
    "                    'sqlalchemy',\\\n",
    "                    'alembic',\\\n",
    "                    'pyyaml',\\\n",
    "                    'flask' # Flask is needed for API, ensure it's in env\n",
    "                ],\\\n",
    "                'name': 'hres_mcda_env'\\\n",
    "            }\\\n",
    "        )\n",
    "\n",
    "    print(f\"‚úÖ Decision logic has been packaged and registered as model '{MODEL_NAME_MCDA}' in the MLflow Model Registry.\")\n",
    "else:\\\n",
    "    print(\"‚ùå Skipping MCDA model packaging: Dataset is empty.\")"
   ],
   "id": "ac9eb682f419b534"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4828dc0182cd9164"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
